# -------- #
# API Keys #
# -------- #

# generated at https://platform.openai.com/account/api-keys
OPENAI_API_KEY=
# generated at https://replicate.com/account
REPLICATE_API_KEY=
# generated at https://docs.elevenlabs.io/api-reference/quick-start/authentication
ELEVEN_LABS_API_KEY=
# generated at https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=
# generated at https://www.searchapi.io/
SEARCH_API_KEY=
# generated at https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=
# generated through Azure
AZURE_API_KEY=
AZURE_MODEL_ID=
AZURE_ENDPOINT=
AZURE_API_VERSION=2025-01-01-preview
# variables for OpenAI-compatible endpoints (e.g., DeepSeek (https://platform.deepseek.com/api_keys))
OPENAI_COMPATIBLE_API_KEY=
OPENAI_COMPATIBLE_MODEL_NAME=
OPENAI_COMPATIBLE_ENDPOINT=

# --------------------- #
# Project customization #
# --------------------- #

# if true, starts your chat with dummy conversations, defaults your model to debug, and potentially more
NEXT_PUBLIC_IS_DEBUGGING=false
# if true, shows verbose console.log entries, both on the client and the server. Recommended to start with this variable set to true
NEXT_PUBLIC_SHOULD_SHOW_ALL_LOGS=true

# ------------------------- #
# Local model customization #
# ------------------------- #

# this model should be placed in your models folder and can be downloaded here: https://huggingface.co/TheBloke/airoboros-13b-gpt4-GGML/resolve/main/airoboros-13b-gpt4.ggmlv3.q4_0.bin
LOCAL_MODEL_NAME=dolphin-2.6-mistral-7b-dpo-laser.Q4_K_M.gguf
# you can also run a local LLM using an Ollama server (not installed in this project). 
# phi3.5 is a small 3.8b parameter model
LOCAL_OLLAMA_MODEL_NAME=phi3.5
# instead of paying for OpenAI embeddings, you can use local embeddings through Ollama
NEXT_PUBLIC_IS_USING_LOCAL_EMBEDDINGS=false
# if true, the local model will be aborted if running for longer than a specified amount of time
LOCAL_MODEL_SHOULD_TIMEOUT=true
# as a safety mechanism, the back-end will stop the stream if the model is running for a long time. You can set a custom number in milliseconds for when it should do this, but there is a default defined
LOCAL_MODEL_TIMEOUT_LENGTH=

# ------------------- #
# Agent customization #
# ------------------- #

# allows you to mock the list of tasks for consistency. You can find the current list of values in components\agents\agentFunctions.ts
NEXT_PUBLIC_AGENT_TASKS_DATA=REAL

# ---------------- #
# Background video #
# ---------------- #

# a bit silly, but the reasoning and agent modes support adding a custom background video that plays when the AI is running.
# you must use relative paths due to CORS (e.g., NEXT_PUBLIC_REASONING_BACKGROUND_VIDEO_SRC=/videos/background_video.mp4).
# the videos folder is gitignored
NEXT_PUBLIC_REASONING_BACKGROUND_VIDEO_SRC=
NEXT_PUBLIC_AGENT_BACKGROUND_VIDEO_SRC=